{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Softmax + Tanh/Sigmoid\n",
    "\n",
    "* Single-Hidden Architecture: \n",
    "$ \\hat{y} = argmax( softmax(w_2\\cdot tahn/sigmoid(w_1\\cdot x + b_1) + b_2 ) ) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# E.G. MNIST (784-30-10) ARCHITECTURE\n",
    "#  argmax(  softmax( w_2  *  tanh/sigmoid( w_1  *  x  +  b_1  )  + b_2 )   )\n",
    "#     |               |                     |      |      |         |      |   \n",
    "#     |             30*10                784*30  784*1   30*1     10*1     |\n",
    "#     |               |                     |______|______|         |      |\n",
    "#     |               |                            |                |      |\n",
    "#     |               |                          30*1               |      | \n",
    "#     |               |____________________________|________________|      |\n",
    "#     |                                            |                       |\n",
    "#     |                                          10*1                      |\n",
    "#     |____________________________________________|_______________________|\n",
    "#                                                  |\n",
    "#                                                  1 (i.e. Pr(y_hat=i|x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Regularization (L1 & L2, Recap)\n",
    "\n",
    "* $ L = L + \\lambda\\parallel\\theta\\parallel_p^p $, where $\\parallel\\theta\\parallel_p = (\\sum_{j=0}^{|\\theta|} |\\theta_j|^p)^\\frac{1}{p}$\n",
    "* L1/2 Regularization: $p = 1$/$p=2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import six.moves.cPickle as pickle\n",
    "import gzip, os, sys, timeit\n",
    "os.chdir(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/ML_GENERAL/PYTHON_IMPL\")\n",
    "# sys.path.append(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/ML_GENERAL/PYTHON_IMPL/ACCESSORIES\")\n",
    "# sys.path.append(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/ML_GENERAL/PYTHON_IMPL/DATA\")\n",
    "    # run once is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor import tanh\n",
    "from theano import function, shared\n",
    "from theano.tensor.nnet import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from logistic import LogisticRegression, shared_dataset, load_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class HiddenLayer:\n",
    "    \n",
    "    def __init__(self, rng, inpt, nIn, nOut, activation=tanh):\n",
    "        # rng: np.random.RandomState, a rand. generator.\n",
    "        # inpt: symbolic tensor, shape=(nDataSize, nIn) (e.g. mnist: 50,000 * 784).\n",
    "        # nIn, nOut: dimension of input; number of hidden neurons.\n",
    "        self.inpt = inpt\n",
    "        self.W = shared(np.asarray(rng.uniform(low=-np.sqrt(6./(nIn+nOut)), \n",
    "                                               high=np.sqrt(6./(nIn+nOut)), \n",
    "                                               size=(nIn,nOut)),\n",
    "                                   dtype=theano.config.floatX),\n",
    "                        name='W', borrow=True)\n",
    "        self.b = shared(np.zeros((nOut,), dtype=theano.config.floatX),\n",
    "                        name='b', borrow=True)\n",
    "        self.output = activation(T.dot(inpt, self.W) + self.b)\n",
    "        self.params = [self.W, self.b]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self, rng, inpt, nIn, nHidden, nOut):\n",
    "        self.hiddenLayer = HiddenLayer(rng=rng, inpt=inpt, nIn=nIn, nOut=nHidden, activation=tanh)\n",
    "        self.logregLayer = LogisticRegression(inpt=self.hiddenLayer.output, nIn=nHidden, nOut=nOut)\n",
    "        self.L1 = ( abs(self.hiddenLayer.W).sum() + abs(self.logregLayer.W).sum() )\n",
    "        self.L2 = ( (self.hiddenLayer.W**2).sum() + (self.logregLayer.W**2).sum() )\n",
    "        self.nll = self.logregLayer.nll \n",
    "        self.errors = self.logregLayer.errors\n",
    "        self.params = self.hiddenLayer.params + self.logregLayer.params\n",
    "        self.inpt = inpt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_mlp(lr=.01, L1=.0, L2=.0001, epochs=1000, data=load_mnist, batchSize=20, nHidden=500):\n",
    "    \n",
    "    datasets = load_mnist()\n",
    "    X_train, Y_train = datasets[0]\n",
    "    X_dev, Y_dev = datasets[1]\n",
    "    X_test, Y_test = datasets[2]\n",
    "    \n",
    "    nTrainBatches = X_train.get_value(borrow=True).shape[0] / batchSize # // if Python 3.\n",
    "    nDevBatches = X_dev.get_value(borrow=True).shape[0] / batchSize\n",
    "    nTestBatches = X_test.get_value(borrow=True).shape[0] / batchSize\n",
    "    \n",
    "    print \"... building the model\"\n",
    "    \n",
    "    index = T.iscalar() # index of a batch.\n",
    "    x = T.matrix('x')\n",
    "    y = T.ivector('y')\n",
    "    \n",
    "    rng = np.random.RandomState(1234)\n",
    "    \n",
    "    classifier = MLP(rng=rng, inpt=x, nIn=28*28, nHidden=nHidden, nOut=10)\n",
    "    cost = ( classifier.nll(y) + L1*classifier.L1 + L2*classifier.L2 )\n",
    "    \n",
    "    test_model = function(inputs=[index], outputs=classifier.errors(y),\n",
    "                          givens = {x: X_test[index*batchSize: (index+1)*batchSize],\n",
    "                                    y: Y_test[index*batchSize: (index+1)*batchSize]})\n",
    "    dev_model = function(inputs=[index], outputs=classifier.errors(y),\n",
    "                         givens = {x: X_dev[index*batchSize: (index+1)*batchSize],\n",
    "                                   y: Y_dev[index*batchSize: (index+1)*batchSize]})\n",
    "    \n",
    "    gparams = [T.grad(cost, param) for param in classifier.params]\n",
    "    updates = [(param, param-lr*gparam) for param,gparam in zip(classifier.params, gparams)]\n",
    "    \n",
    "    train_model = function(inputs=[index], outputs=cost, updates=updates, \n",
    "                           givens = {x: X_train[index*batchSize: (index+1)*batchSize],\n",
    "                                     y: Y_train[index*batchSize: (index+1)*batchSize]})\n",
    "    \n",
    "    print \"... training the model\"\n",
    "    \n",
    "    patience = 10000\n",
    "    patienceIncrease = 2\n",
    "    improvementThreshold = .995\n",
    "    validationFrequency = min(nTrainBatches, patience/2)\n",
    "    bestValidationLoss = np.inf\n",
    "    bestIter = 0\n",
    "    testScore = 0.\n",
    "    startTime = timeit.default_timer()\n",
    "    \n",
    "    epoch = 0\n",
    "    doneLooping = False\n",
    "    \n",
    "    while (epoch < epochs) and (not doneLooping):\n",
    "        epoch += 1\n",
    "        for batchIndex in range(nTrainBatches):\n",
    "            avgBatchCost = train_model(batchIndex)\n",
    "            iter = (epoch-1)*nTrainBatches + batchIndex\n",
    "            if (iter+1) % validationFrequency == 0:\n",
    "                validationLosses = [dev_model(i) for i in range(nDevBatches)]\n",
    "                thisValidationLoss = np.mean(validationLosses)\n",
    "                print \"Epoch %i, Batch %i/%i, Validation Error %f %%\" % (epoch,batchIndex+1,\n",
    "                                                                         nTrainBatches,thisValidationLoss*100.)\n",
    "                if thisValidationLoss < bestValidationLoss:\n",
    "                    if thisValidationLoss < bestValidationLoss*improvementThreshold:\n",
    "                        patience = max(patience, iter*patienceIncrease)\n",
    "                        bestValidationLoss = thisValidationLoss\n",
    "                        bestIter = iter\n",
    "                        testLosses = [test_model(i) for i in range(nTestBatches)]\n",
    "                        testScore = np.mean(testLosses)\n",
    "                        print \"Epoch %i, Batch %i/%i, Test Error of Best: %f %%\" % (epoch,batchIndex,\n",
    "                                                                                    nTrainBatches,testScore*100.)\n",
    "                if patience <= iter:\n",
    "                    doneLooping = True\n",
    "                    break\n",
    "    endTime = timeit.default_timer()\n",
    "    print \"Optimization Done, Best Validation Score: %f %% (at iter %i, best test performance %f %%)\" % (bestValidationLoss*100,\n",
    "                                                                                                         bestIter+1,\n",
    "                                                                                                         testScore*100.)\n",
    "    print \"Run Time: %f\" % (endTime-startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_mlp() \n",
    "#  ...\n",
    "#  Epoch 991, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 992, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 993, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 994, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 995, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 996, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 997, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 998, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 999, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Epoch 1000, Batch 2500/2500, Validation Error 1.700000 %\n",
    "#  Optimization Done, Best Validation Score: 1.680000 % (at iter 2050000, best test performance 1.650000 %)\n",
    "#  Run Time: 4635.659076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
