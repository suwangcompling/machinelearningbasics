{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import six.moves.cPickle as pickle\n",
    "import pickle as pkl\n",
    "import copy_reg\n",
    "import gzip, os, sys, timeit\n",
    "os.chdir(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/ML_GENERAL/PYTHON_IMPL\")\n",
    "# sys.path.append(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/ML_GENERAL/PYTHON_IMPL/ACCESSORIES\")\n",
    "# sys.path.append(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/ML_GENERAL/PYTHON_IMPL/DATA\")\n",
    "    # run once is enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor import tanh\n",
    "from theano import function, shared\n",
    "from theano.tensor.nnet import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class HiddenLayer:\n",
    "    \n",
    "    def __init__(self, rng, inpt, nIn, nOut, activation=tanh):\n",
    "        self.inpt = inpt\n",
    "        self.W = shared(np.asarray(rng.uniform(low=-np.sqrt(6./(nIn+nOut)), \n",
    "                                               high=np.sqrt(6./(nIn+nOut)), \n",
    "                                               size=(nIn,nOut)),\n",
    "                                   dtype=theano.config.floatX),\n",
    "                        name='W', borrow=True)\n",
    "        self.b = shared(np.zeros((nOut,), dtype=theano.config.floatX),\n",
    "                        name='b', borrow=True)\n",
    "        self.output = activation(T.dot(inpt, self.W) + self.b)\n",
    "        self.params = [self.W, self.b]\n",
    "\n",
    "class OutputLayer:\n",
    "    \n",
    "    def __init__(self, inpt, nIn, nOut):\n",
    "        self.inpt = inpt\n",
    "        self.W = shared(value=np.zeros((nIn,nOut),dtype=theano.config.floatX), \n",
    "                        name='W', borrow=True) \n",
    "        self.b = shared(value=np.zeros((nOut,),dtype=theano.config.floatX), \n",
    "                        name='b', borrow=True) \n",
    "        self.pYgivenX = softmax(T.dot(inpt, self.W) + self.b)\n",
    "        self.yHat = T.argmax(self.pYgivenX, axis=1)\n",
    "        self.params = [self.W, self.b]      \n",
    "        \n",
    "    def nll(self, y): \n",
    "        return -T.mean(T.log(self.pYgivenX)[T.arange(y.shape[0]), y])\n",
    "    \n",
    "    def errors(self, y):\n",
    "        assert y.ndim == self.yHat.ndim\n",
    "        assert y.dtype.startswith('int')\n",
    "        return T.mean(T.neq(self.yHat, y)) \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    \n",
    "    def __init__(self, inpt, sizes, rng=np.random.RandomState(0), hiddenActivation=tanh):\n",
    "        assert sizes >= 3\n",
    "        self.numLayers = len(sizes)\n",
    "        self.layers = [ HiddenLayer(rng=rng,inpt=inpt,nIn=nIn,nOut=nOut) for nIn,nOut in zip(sizes[:-2],sizes[1:]) ]\n",
    "        self.layers.append(OutputLayer(inpt=self.layers[-1].output,nIn=sizes[-2],nOut=sizes[-1]))\n",
    "        self.nll, self.errors = self.layers[-1].nll, self.layers[-1].errors\n",
    "        self.params = []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "        self.inpt = inpt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sgd(train, sizes, lr=.01, epochs=100, batchSize=20, validation=None, test=None):\n",
    "    \n",
    "    print \"... preparing data\"\n",
    "    \n",
    "    assert len(train) == 2\n",
    "    X_train, Y_train = train\n",
    "    \n",
    "    print \"... building the model\"\n",
    "    \n",
    "    index = T.iscalar()\n",
    "    x = T.matrix('x')\n",
    "    y = T.ivector('y')\n",
    "    rng = np.random.RandomState(0)\n",
    "    classifier = MLP(inpt=x, sizes=sizes)\n",
    "    cost = classifier.nll(y)\n",
    "    gparams = [T.grad(cost, param) for param in classifier.params]\n",
    "    updates = [(param, param-lr*gparam) for param,gparam in zip(classifier.params,gparams)]\n",
    "    train_model = function(inputs=[index], outputs=cost, updates=updates,\n",
    "                           givens = {x: X_train[index*batchSize: (index+1)*batchSize],\n",
    "                                     y: Y_train[index*batchSize: (index+1)*batchSize]})\n",
    "    nTrainBatches = X_train.get_value(borrow=True).shape[0] / batchSize\n",
    "    if validation is not None: \n",
    "        assert len(validation) == 2\n",
    "        X_dev, Y_dev = validation\n",
    "        dev_model = function(inputs=[index], outputs=classifier.errors(y),\n",
    "                             givens = {x: X_dev[index*batchSize: (index+1)*batchSize],\n",
    "                                       y: Y_dev[index*batchSize: (index+1)*batchSize]})\n",
    "        nDevBatches = X_dev.get_value(borrow=True).shape[0] / batchSize\n",
    "    if test is not None: \n",
    "        assert len(test) == 2\n",
    "        X_test, Y_test = test\n",
    "        test_model = function(inputs=[index], outputs=classifier.errors(y),\n",
    "                              givens = {x: X_test[index*batchSize: (index+1)*batchSize],\n",
    "                                        y: Y_test[index*batchSize: (index+1)*batchSize]})   \n",
    "        nTestBatches = X_test.get_value(borrow=True).shape[0] / batchSize\n",
    "    \n",
    "    print \"... training the model\"\n",
    "    \n",
    "    patience = 10000\n",
    "    patienceIncrease = 2\n",
    "    improvmentThreshold = .995\n",
    "    validationFrequency = min(nTrainBatches, patience/2)\n",
    "    bestValidationLoss = np.inf\n",
    "    bestIter = 0\n",
    "    bestScore = 0.\n",
    "    \n",
    "    epoch = 0\n",
    "    doneLooping = False\n",
    "    \n",
    "    while (epoch < epochs) and (not doneLooping):\n",
    "        epoch += 1\n",
    "        for batchIndex in range(nTrainBatches):\n",
    "            avgBatchCost = train_model(batchIndex)\n",
    "            iter = (epoch-1)*nTrainBatches + batchIndex\n",
    "            if validation is not None and (iter+1) % validationFrequency == 0:\n",
    "                validationLosses = [dev_model(i) for i in range(nDevBatches)]\n",
    "                thisValidationLoss = np.mean(validationLosses)\n",
    "                print \"Epoch %i, Batch %i/%i, Validation Error %f%%\" % (epoch,batchIndex+1,\n",
    "                                                                         nTrainBatches,thisValidationLoss*100.)\n",
    "                if test is not None and thisValidationLoss < bestValidationLoss:\n",
    "                    if thisValidationLoss < bestValidationLoss*improvmentThreshold:\n",
    "                        patience = max(patience, iter*patienceIncrease)\n",
    "                        bestValidationLoss = thisValidationLoss\n",
    "                        bestIter = iter\n",
    "                        testLosses = [test_model(i) for i in range(nTestBatches)]\n",
    "                        testScore = np.mean(testLosses)\n",
    "                        print \"Epoch %i, Batch %i/%i, Test Error of Best: %f%%\" % (epoch,batchIndex+1,\n",
    "                                                                                    nTrainBatches,testScore*100.)\n",
    "                        #  with open('best_model.pkl','wb') as f:\n",
    "                        #      pkl.dump(classifier, f)\n",
    "                if patience <= iter:\n",
    "                    doneLooping = True\n",
    "                    break\n",
    "    if validation is not None: #\"Optimization Done, Best Validation Score: %f%%\" %\n",
    "        print \"Optimization Done, Best Validation Score: {}%\".format(bestValidationLoss*100)\n",
    "    if test is not None:\n",
    "        print \"Best Test performance achieved at iter %i: %f%%\" % (bestIter+1,testScore*100.)  \n",
    "    return bestValidationLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shared_dataset(data, borrow=True):\n",
    "    X, Y = data\n",
    "    sharedX = theano.shared(np.asarray(X,dtype=theano.config.floatX), borrow=borrow)\n",
    "    sharedY = theano.shared(np.asarray(Y,dtype=theano.config.floatX), borrow=borrow)\n",
    "    return sharedX, T.cast(sharedY, 'int32') \n",
    "def load_mnist():\n",
    "    import os\n",
    "    os.chdir(\"/Users/jacobsw/Desktop/IMPLEMENTATION_CAMP/CODE/BASIC_TOPICS/ML_GENERAL/PYTHON_IMPL/DATA/\")\n",
    "    with gzip.open('mnist.pkl.gz') as f:\n",
    "        data_train, data_dev, data_test = pickle.load(f)\n",
    "    X_train, Y_train = shared_dataset(data_train)\n",
    "    X_dev, Y_dev = shared_dataset(data_dev)\n",
    "    X_test, Y_test = shared_dataset(data_test)\n",
    "    \n",
    "    return [(X_train, Y_train), (X_dev, Y_dev), (X_test, Y_test)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, dev, test = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... preparing data\n",
      "... building the model\n",
      "... training the model\n",
      "Epoch 1, Batch 2500/2500, Validation Error 11.470000%\n",
      "Epoch 1, Batch 2500/2500, Test Error of Best: 11.570000%\n",
      "Epoch 2, Batch 2500/2500, Validation Error 9.120000%\n",
      "Epoch 2, Batch 2500/2500, Test Error of Best: 9.170000%\n",
      "Epoch 3, Batch 2500/2500, Validation Error 8.210000%\n",
      "Epoch 3, Batch 2500/2500, Test Error of Best: 8.380000%\n",
      "Epoch 4, Batch 2500/2500, Validation Error 7.450000%\n",
      "Epoch 4, Batch 2500/2500, Test Error of Best: 7.520000%\n",
      "Epoch 5, Batch 2500/2500, Validation Error 6.930000%\n",
      "Epoch 5, Batch 2500/2500, Test Error of Best: 7.080000%\n",
      "Epoch 6, Batch 2500/2500, Validation Error 6.520000%\n",
      "Epoch 6, Batch 2500/2500, Test Error of Best: 6.690000%\n",
      "Epoch 7, Batch 2500/2500, Validation Error 6.200000%\n",
      "Epoch 7, Batch 2500/2500, Test Error of Best: 6.270000%\n",
      "Epoch 8, Batch 2500/2500, Validation Error 5.800000%\n",
      "Epoch 8, Batch 2500/2500, Test Error of Best: 5.950000%\n",
      "Epoch 9, Batch 2500/2500, Validation Error 5.530000%\n",
      "Epoch 9, Batch 2500/2500, Test Error of Best: 5.680000%\n",
      "Epoch 10, Batch 2500/2500, Validation Error 5.280000%\n",
      "Epoch 10, Batch 2500/2500, Test Error of Best: 5.450000%\n",
      "Epoch 11, Batch 2500/2500, Validation Error 5.090000%\n",
      "Epoch 11, Batch 2500/2500, Test Error of Best: 5.260000%\n",
      "Epoch 12, Batch 2500/2500, Validation Error 4.920000%\n",
      "Epoch 12, Batch 2500/2500, Test Error of Best: 5.120000%\n",
      "Epoch 13, Batch 2500/2500, Validation Error 4.820000%\n",
      "Epoch 13, Batch 2500/2500, Test Error of Best: 4.970000%\n",
      "Epoch 14, Batch 2500/2500, Validation Error 4.740000%\n",
      "Epoch 14, Batch 2500/2500, Test Error of Best: 4.860000%\n",
      "Epoch 15, Batch 2500/2500, Validation Error 4.600000%\n",
      "Epoch 15, Batch 2500/2500, Test Error of Best: 4.750000%\n",
      "Epoch 16, Batch 2500/2500, Validation Error 4.480000%\n",
      "Epoch 16, Batch 2500/2500, Test Error of Best: 4.730000%\n",
      "Epoch 17, Batch 2500/2500, Validation Error 4.410000%\n",
      "Epoch 17, Batch 2500/2500, Test Error of Best: 4.710000%\n",
      "Epoch 18, Batch 2500/2500, Validation Error 4.340000%\n",
      "Epoch 18, Batch 2500/2500, Test Error of Best: 4.590000%\n",
      "Epoch 19, Batch 2500/2500, Validation Error 4.280000%\n",
      "Epoch 19, Batch 2500/2500, Test Error of Best: 4.490000%\n",
      "Epoch 20, Batch 2500/2500, Validation Error 4.250000%\n",
      "Epoch 20, Batch 2500/2500, Test Error of Best: 4.390000%\n",
      "Epoch 21, Batch 2500/2500, Validation Error 4.180000%\n",
      "Epoch 21, Batch 2500/2500, Test Error of Best: 4.300000%\n",
      "Epoch 22, Batch 2500/2500, Validation Error 4.140000%\n",
      "Epoch 22, Batch 2500/2500, Test Error of Best: 4.200000%\n",
      "Epoch 23, Batch 2500/2500, Validation Error 4.100000%\n",
      "Epoch 23, Batch 2500/2500, Test Error of Best: 4.190000%\n",
      "Epoch 24, Batch 2500/2500, Validation Error 4.070000%\n",
      "Epoch 24, Batch 2500/2500, Test Error of Best: 4.150000%\n",
      "Epoch 25, Batch 2500/2500, Validation Error 4.030000%\n",
      "Epoch 25, Batch 2500/2500, Test Error of Best: 4.110000%\n",
      "Epoch 26, Batch 2500/2500, Validation Error 4.000000%\n",
      "Epoch 26, Batch 2500/2500, Test Error of Best: 4.060000%\n",
      "Epoch 27, Batch 2500/2500, Validation Error 3.960000%\n",
      "Epoch 27, Batch 2500/2500, Test Error of Best: 3.980000%\n",
      "Epoch 28, Batch 2500/2500, Validation Error 3.920000%\n",
      "Epoch 28, Batch 2500/2500, Test Error of Best: 3.930000%\n",
      "Epoch 29, Batch 2500/2500, Validation Error 3.880000%\n",
      "Epoch 29, Batch 2500/2500, Test Error of Best: 3.890000%\n",
      "Epoch 30, Batch 2500/2500, Validation Error 3.840000%\n",
      "Epoch 30, Batch 2500/2500, Test Error of Best: 3.870000%\n",
      "Epoch 31, Batch 2500/2500, Validation Error 3.840000%\n",
      "Epoch 32, Batch 2500/2500, Validation Error 3.810000%\n",
      "Epoch 32, Batch 2500/2500, Test Error of Best: 3.870000%\n",
      "Epoch 33, Batch 2500/2500, Validation Error 3.800000%\n",
      "Epoch 34, Batch 2500/2500, Validation Error 3.790000%\n",
      "Epoch 34, Batch 2500/2500, Test Error of Best: 3.840000%\n",
      "Epoch 35, Batch 2500/2500, Validation Error 3.750000%\n",
      "Epoch 35, Batch 2500/2500, Test Error of Best: 3.830000%\n",
      "Epoch 36, Batch 2500/2500, Validation Error 3.730000%\n",
      "Epoch 36, Batch 2500/2500, Test Error of Best: 3.790000%\n",
      "Epoch 37, Batch 2500/2500, Validation Error 3.710000%\n",
      "Epoch 37, Batch 2500/2500, Test Error of Best: 3.750000%\n",
      "Epoch 38, Batch 2500/2500, Validation Error 3.710000%\n",
      "Epoch 39, Batch 2500/2500, Validation Error 3.720000%\n",
      "Epoch 40, Batch 2500/2500, Validation Error 3.720000%\n",
      "Epoch 41, Batch 2500/2500, Validation Error 3.710000%\n",
      "Epoch 42, Batch 2500/2500, Validation Error 3.720000%\n",
      "Epoch 43, Batch 2500/2500, Validation Error 3.730000%\n",
      "Epoch 44, Batch 2500/2500, Validation Error 3.690000%\n",
      "Epoch 44, Batch 2500/2500, Test Error of Best: 3.630000%\n",
      "Epoch 45, Batch 2500/2500, Validation Error 3.670000%\n",
      "Epoch 45, Batch 2500/2500, Test Error of Best: 3.680000%\n",
      "Epoch 46, Batch 2500/2500, Validation Error 3.690000%\n",
      "Epoch 47, Batch 2500/2500, Validation Error 3.650000%\n",
      "Epoch 47, Batch 2500/2500, Test Error of Best: 3.710000%\n",
      "Epoch 48, Batch 2500/2500, Validation Error 3.700000%\n",
      "Epoch 49, Batch 2500/2500, Validation Error 3.690000%\n",
      "Epoch 50, Batch 2500/2500, Validation Error 3.700000%\n",
      "Epoch 51, Batch 2500/2500, Validation Error 3.690000%\n",
      "Epoch 52, Batch 2500/2500, Validation Error 3.680000%\n",
      "Epoch 53, Batch 2500/2500, Validation Error 3.670000%\n",
      "Epoch 54, Batch 2500/2500, Validation Error 3.660000%\n",
      "Epoch 55, Batch 2500/2500, Validation Error 3.660000%\n",
      "Epoch 56, Batch 2500/2500, Validation Error 3.660000%\n",
      "Epoch 57, Batch 2500/2500, Validation Error 3.670000%\n",
      "Epoch 58, Batch 2500/2500, Validation Error 3.700000%\n",
      "Epoch 59, Batch 2500/2500, Validation Error 3.660000%\n",
      "Epoch 60, Batch 2500/2500, Validation Error 3.630000%\n",
      "Epoch 60, Batch 2500/2500, Test Error of Best: 3.600000%\n",
      "Epoch 61, Batch 2500/2500, Validation Error 3.640000%\n",
      "Epoch 62, Batch 2500/2500, Validation Error 3.620000%\n",
      "Epoch 63, Batch 2500/2500, Validation Error 3.630000%\n",
      "Epoch 64, Batch 2500/2500, Validation Error 3.600000%\n",
      "Epoch 64, Batch 2500/2500, Test Error of Best: 3.610000%\n",
      "Epoch 65, Batch 2500/2500, Validation Error 3.560000%\n",
      "Epoch 65, Batch 2500/2500, Test Error of Best: 3.590000%\n",
      "Epoch 66, Batch 2500/2500, Validation Error 3.540000%\n",
      "Epoch 66, Batch 2500/2500, Test Error of Best: 3.570000%\n",
      "Epoch 67, Batch 2500/2500, Validation Error 3.520000%\n",
      "Epoch 67, Batch 2500/2500, Test Error of Best: 3.580000%\n",
      "Epoch 68, Batch 2500/2500, Validation Error 3.500000%\n",
      "Epoch 68, Batch 2500/2500, Test Error of Best: 3.570000%\n",
      "Epoch 69, Batch 2500/2500, Validation Error 3.490000%\n",
      "Epoch 70, Batch 2500/2500, Validation Error 3.490000%\n",
      "Epoch 71, Batch 2500/2500, Validation Error 3.490000%\n",
      "Epoch 72, Batch 2500/2500, Validation Error 3.460000%\n",
      "Epoch 72, Batch 2500/2500, Test Error of Best: 3.590000%\n",
      "Epoch 73, Batch 2500/2500, Validation Error 3.460000%\n",
      "Epoch 74, Batch 2500/2500, Validation Error 3.460000%\n",
      "Epoch 75, Batch 2500/2500, Validation Error 3.460000%\n",
      "Epoch 76, Batch 2500/2500, Validation Error 3.450000%\n",
      "Epoch 77, Batch 2500/2500, Validation Error 3.450000%\n",
      "Epoch 78, Batch 2500/2500, Validation Error 3.450000%\n",
      "Epoch 79, Batch 2500/2500, Validation Error 3.460000%\n",
      "Epoch 80, Batch 2500/2500, Validation Error 3.470000%\n",
      "Epoch 81, Batch 2500/2500, Validation Error 3.430000%\n",
      "Epoch 81, Batch 2500/2500, Test Error of Best: 3.550000%\n",
      "Epoch 82, Batch 2500/2500, Validation Error 3.410000%\n",
      "Epoch 82, Batch 2500/2500, Test Error of Best: 3.540000%\n",
      "Epoch 83, Batch 2500/2500, Validation Error 3.420000%\n",
      "Epoch 84, Batch 2500/2500, Validation Error 3.410000%\n",
      "Epoch 85, Batch 2500/2500, Validation Error 3.420000%\n",
      "Epoch 86, Batch 2500/2500, Validation Error 3.420000%\n",
      "Epoch 87, Batch 2500/2500, Validation Error 3.430000%\n",
      "Epoch 88, Batch 2500/2500, Validation Error 3.390000%\n",
      "Epoch 88, Batch 2500/2500, Test Error of Best: 3.560000%\n",
      "Epoch 89, Batch 2500/2500, Validation Error 3.390000%\n",
      "Epoch 90, Batch 2500/2500, Validation Error 3.400000%\n",
      "Epoch 91, Batch 2500/2500, Validation Error 3.370000%\n",
      "Epoch 91, Batch 2500/2500, Test Error of Best: 3.530000%\n",
      "Epoch 92, Batch 2500/2500, Validation Error 3.390000%\n",
      "Epoch 93, Batch 2500/2500, Validation Error 3.400000%\n",
      "Epoch 94, Batch 2500/2500, Validation Error 3.410000%\n",
      "Epoch 95, Batch 2500/2500, Validation Error 3.410000%\n",
      "Epoch 96, Batch 2500/2500, Validation Error 3.410000%\n",
      "Epoch 97, Batch 2500/2500, Validation Error 3.410000%\n",
      "Epoch 98, Batch 2500/2500, Validation Error 3.370000%\n",
      "Epoch 99, Batch 2500/2500, Validation Error 3.370000%\n",
      "Epoch 100, Batch 2500/2500, Validation Error 3.370000%\n",
      "Optimization Done, Best Validation Score: 3.37%\n",
      "Best Test performance achieved at iter 227500: 3.530000%\n",
      "CPU times: user 1min 24s, sys: 13.5 s, total: 1min 38s\n",
      "Wall time: 1min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "t = sgd(train, [784, 30, 10], validation=dev, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
